import dotenv from 'dotenv';
import { OpenAIAPIClient } from './server/src/clients/OpenAIAPIClient.js';
import { PromptOptimizationService } from './server/src/services/PromptOptimizationService.js';

// Load environment variables
dotenv.config();

const modes = [
  {
    name: 'Research Mode',
    mode: 'research',
    prompt: 'research best practices for PostgreSQL query optimization',
  },
  {
    name: 'Socratic Mode',
    mode: 'socratic',
    prompt: 'teach me about React hooks and when to use them',
  },
  {
    name: 'Default/Optimize Mode',
    mode: 'optimize',
    prompt: 'create a Python script to analyze log files for errors',
  },
];

async function testMode(client, service, testCase) {
  console.log(`\n${'='.repeat(80)}`);
  console.log(`🧪 Testing ${testCase.name}`);
  console.log(`${'='.repeat(80)}`);
  console.log(`📝 Prompt: "${testCase.prompt}"`);
  console.log(`⚙️  Mode: ${testCase.mode}\n`);

  try {
    const result = await service.optimize({
      prompt: testCase.prompt,
      mode: testCase.mode,
      // No context provided - will trigger auto-inference for modes that support it
    });

    console.log('✅ OPTIMIZED OUTPUT (First 500 characters):');
    console.log('-'.repeat(80));
    console.log(result.substring(0, 500) + '...\n');

    // Check for domain-specific content
    const hasSpecificContent =
      (testCase.mode === 'research' && (result.includes('PostgreSQL') || result.includes('query'))) ||
      (testCase.mode === 'socratic' && (result.includes('React') || result.includes('hooks'))) ||
      (testCase.mode === 'optimize' && (result.includes('Python') || result.includes('log')));

    if (hasSpecificContent) {
      console.log('✅ Domain-specific content detected!');
    } else {
      console.log('⚠️  Domain-specific content NOT detected - may need investigation');
    }

  } catch (error) {
    console.error(`❌ ${testCase.name} failed:`, error.message);
    throw error;
  }
}

async function runTests() {
  console.log('🚀 Testing Phase 1: Two-Stage Domain-Specific Content Generation');
  console.log('Testing Research, Socratic, and Default/Optimize modes\n');

  // Initialize OpenAI client
  const client = new OpenAIAPIClient(process.env.OPENAI_API_KEY, {
    timeout: 60000,
    model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
  });

  // Initialize optimization service
  const service = new PromptOptimizationService(client);

  for (const testCase of modes) {
    await testMode(client, service, testCase);
  }

  console.log(`\n${'='.repeat(80)}`);
  console.log('🎯 All tests complete!');
  console.log(`${'='.repeat(80)}\n`);
  console.log('Summary:');
  console.log('✅ Research mode: Generates domain-specific source types, methodologies, quality criteria, and biases');
  console.log('✅ Socratic mode: Generates domain-specific prerequisites, misconceptions, analogies, and milestones');
  console.log('✅ Default/Optimize mode: Generates domain-specific technical specs, anti-patterns, success metrics, and constraints');
  console.log('\nAll three modes now use two-stage prompt chaining for domain-specific optimization!');
}

// Run the tests
runTests().catch(error => {
  console.error('❌ Test suite failed:', error);
  process.exit(1);
});
