# Prompt Optimizer - Project Overview

> **ğŸš€ For quick start and installation, see [README.md](README.md)**

This document provides comprehensive documentation about Prompt Optimizer, including detailed feature explanations, use cases, architecture, and more.

---

## What Is Prompt Optimizer?

**Prompt Optimizer** is an AI-powered platform that transforms simple, vague prompts into detailed, highly-effective instructions for AI video generation models. It's like having an expert cinematographer and prompt engineer working alongside you, instantly improving your prompts to get better results from AI video systems like Sora, Veo3, RunwayML, Kling, and Luma.

### The Problem It Solves

**Before Prompt Optimizer:**
- You write: `"A person walking on a beach"`
- AI video model gives you: Generic, inconsistent video with poor composition

**After Prompt Optimizer:**
- System transforms it to: `"Wide shot: A woman in her early 30s with flowing auburn hair and a white linen dress walks barefoot along a pristine beach at golden hour, gentle waves lapping at her feet as seabirds circle overhead. Camera: Smooth lateral tracking shot at a consistent distance, maintaining the subject in the right third of the frame. Lighting: Warm golden hour backlight creates a luminous glow around her silhouette..."`
- AI video model gives you: Cinematic, technically-accurate video with proper composition, lighting, and camera movement

### Why This Matters

Research shows that prompt quality dramatically affects AI output:
- **Poor prompts**: Vague, incomplete responses
- **Good prompts**: Detailed, accurate, usable results
- **Expert prompts**: Production-ready output that saves hours of work

The problem? Most people don't know how to write expert-level prompts. **Prompt Optimizer solves this.**

---

## Core Concept

### The Magic Formula

```
Your Simple Idea â†’ Prompt Optimizer â†’ Expert-Level Prompt â†’ AI Model â†’ Better Results
```

### What Makes It Different

1. **Intelligence, Not Templates**: Uses AI to understand intent and context
2. **Video-Specific Optimization**: Specialized for AI video generation with cinematic expertise
3. **Real-Time Enhancement**: Interactive highlighting and suggestions as you type
4. **Technical Precision**: Camera angles, lighting, shot composition, and film style references
5. **Production-Ready**: Enterprise architecture with monitoring, caching, and failover

---

## Key Features

### 1. Video Prompt Optimization

Specialized optimization strategy designed specifically for AI video generation platforms:
**Use for:** Sora, Veo3, RunwayML, Kling, Luma Dream Machine

**Specialized for:** Cinematic AI video generation with technical precision

**Example:**
```
Input:  "A person walking on a beach"
Output: "Wide shot: A woman in her early 30s with flowing auburn
        hair and a white linen dress walks barefoot along a
        pristine beach at golden hour, gentle waves lapping at
        her feet as seabirds circle overhead.

        Camera: Smooth lateral tracking shot at a consistent
        distance, maintaining the subject in the right third of
        the frame. Camera height at eye level, moving parallel
        to the shoreline.

        Lighting: Warm golden hour backlight creates a luminous
        glow around her silhouette, with soft fill light
        reflecting off the wet sand. The sun sits low on the
        horizon, creating long shadows and rim lighting on her
        hair.

        Style: Cinematic aesthetic reminiscent of Terrence
        Malick's contemplative cinematography. Shot on 35mm film
        with shallow depth of field (f/2.8), keeping the subject
        sharp while the background softly blurs. Natural color
        grading with enhanced warm tones and slightly desaturated
        blues in the ocean.

        [127 words - optimized for AI video generation]"
```

---

### 2. Intelligent Span Labeling

**Real-time text categorization** that highlights different parts of your prompt:

#### How It Works

As you type or after optimization, the system automatically:
1. Analyzes the text semantically
2. Identifies key elements (subjects, actions, locations, camera angles, lighting, etc.)
3. Highlights each element with color-coded categories
4. Assigns confidence scores to each classification

#### Example

For video prompt: `"A woman walks on a beach at sunset"`

**Highlighted Spans:**
- ğŸŸ¦ **"woman"** â†’ Subject (Person) - 95% confidence
- ğŸŸ© **"walks"** â†’ Action (Movement) - 92% confidence
- ğŸŸ¨ **"beach"** â†’ Location (Outdoor) - 89% confidence
- ğŸŸ§ **"sunset"** â†’ Time (Day Part) - 94% confidence

#### Why This Matters

- **Visual Feedback**: See exactly what the AI understands
- **Quality Checking**: Identify missing or weak elements
- **Interactive Enhancement**: Click any span to get improvement suggestions
- **Learning Tool**: Understand prompt structure through visualization

#### Technical Features

- **Dynamic Taxonomy**: 50+ categorization types across multiple domains
- **Multi-Provider Support**: Works with OpenAI, Groq, and Gemini
- **Performance Optimized**:
  - Chunked processing for large texts
  - Substring position caching
  - Batch API (60% reduction in API calls)
- **Automatic Validation**: Schema validation with auto-repair

---

### 3. Interactive Enhancement System

**Click-to-improve** functionality that provides AI-powered suggestions for any highlighted text.

#### How It Works

1. **Select any highlighted text** in your optimized prompt
2. **Get 3-5 AI-generated alternatives** that:
   - Add more detail
   - Improve specificity
   - Maintain context
   - Align with the category
3. **Click to replace** or use as inspiration
4. **Iteratively refine** until perfect

#### Example Enhancement Flow

**Original:** `"a person walking"`

**Click â†’ Get Suggestions:**
1. `"a woman in her 30s with flowing auburn hair walking gracefully"`
   - *Adds demographic, visual detail, movement quality*

2. `"an elderly man with weathered features walking slowly with a cane"`
   - *Different demographic, pace, props for character depth*

3. `"a young couple walking hand-in-hand"`
   - *Introduces relationship dynamic, physical interaction*

**Custom Request:**
- Type: `"make it more mysterious"`
- Get: `"a shadowy figure in a dark coat walking purposefully through fog"`

#### Features

- **Context-Aware**: Understands surrounding text and original intent
- **Category-Aligned**: Suggestions match the semantic category
- **Edit History Tracking**: Maintains consistency across multiple edits
- **Simple/Complex Modes**: Toggle between faster simple prompts and detailed complex prompts
- **Scene Change Detection**: Warns when changes create inconsistencies (video mode)

---

### 4. Video Concept Builder

**Interactive wizard** for building cinematic AI video prompts element-by-element.

#### The Challenge

AI video models (Sora, Veo3, RunwayML) need **specific technical details**:
- Exact camera angles and movements
- Lighting direction and quality
- Lens specifications
- Shot composition
- Visual style references

Most users don't have cinematography expertise. **The Video Concept Builder solves this.**

#### How It Works

**Element-by-Element Construction:**

1. **Subject**: `"Who or what is in the scene?"`
   - AI suggests: Detailed character descriptions
   - Checks: Visual consistency

2. **Action**: `"What are they doing?"`
   - AI suggests: Clear, filmable actions
   - Checks: Physical feasibility

3. **Location**: `"Where does this take place?"`
   - AI suggests: Rich environmental details
   - Checks: Spatial coherence with subject

4. **Camera**: `"How should this be shot?"`
   - AI suggests: Technical camera specs
   - Provides: Shot type, angle, movement, lens

5. **Lighting**: `"What's the lighting like?"`
   - AI suggests: Lighting setups
   - Provides: Direction, quality, time of day

6. **Style**: `"What's the visual aesthetic?"`
   - AI suggests: Film references, color grading
   - Provides: Mood, tone, artistic style

#### Smart Features

**Compatibility Checking:**
```
âŒ Conflict Detected:
   Subject: "person under a tree"
   Location: "open wheat field"

   Suggestion: "wheat field with a solitary ancient oak"
```

**Scene Completion:**
```
You have: Subject + Location
Missing: Action, Camera, Lighting, Style

AI suggests complete scene with smart defaults
based on your existing choices
```

**Variations Generator:**
```
Your concept: "Quiet character portrait in wheat field"

Variation 1: "Dusty Archives"
- Relocates indoors
- Mysterious discovery mood
- Cool, desaturated palette

Variation 2: "Golden Hour Memories"
- Adds prop storytelling
- Bittersweet nostalgia
- Warmer lighting emphasis
```

**Concept Parser:**
```
Free-form input: "An aging jazz musician plays a final
                  set under flickering club lights"

Parsed into:
- Subject: aging jazz musician with weathered trumpet
- Action: playing a heartfelt final set
- Location: smoke-filled underground jazz club
- Lighting: flickering warm club lights with atmospheric haze
- Mood: melancholic and soulful
- Style: shot on 16mm film
- Camera: medium shot, slow push-in
```

---

### 5. Two-Stage Optimization

**Progressive enhancement** that balances speed with quality.

#### The Problem

**Traditional approach:**
- Single LLM call
- Wait 2-3 seconds
- Get result
- No feedback until complete

**User experience:**
- Feels slow
- No progress indication
- Can't interact during processing

#### The Solution: Two-Stage with Streaming

**Stage 1: Fast Draft (~300ms)**
```
User hits "Optimize"
     â†“
Groq API (Llama 3.1 8B Instant)
     â†“
Sub-second draft appears
     â†“
User sees immediate feedback âœ“
```

**Stage 1.5: Parallel Span Labeling (~200ms)**
```
While draft is generating...
     â†“
Span labeling runs in parallel
     â†“
Highlights appear immediately
     â†“
User can interact with spans âœ“
```

**Stage 2: Refinement (~2s)**
```
In background...
     â†“
OpenAI API (GPT-4o-mini)
     â†“
Enhanced, higher-quality version
     â†“
Smoothly replaces draft âœ“
```

#### Benefits

- **Perceived Speed**: Feels instant (sub-second feedback)
- **Progressive Enhancement**: Good â†’ Better â†’ Best
- **User Engagement**: Can interact immediately with draft
- **Reliability**: If Stage 2 fails, user still has draft
- **Cost Efficiency**: Fast model for draft, premium for refinement

#### Technical Implementation

**Server-Sent Events (SSE):**
```
event: draft
data: {"optimizedPrompt": "...", "metadata": {...}}

event: spans
data: {"spans": [...], "meta": {...}}

event: refined
data: {"optimizedPrompt": "...", "metadata": {...}}

event: done
data: {"complete": true}
```

**Frontend Updates in Real-Time:**
- Draft appears with typewriter animation
- Spans highlight progressively
- Refined version smoothly replaces draft
- Quality score updates

---

### 6. PromptCanvas - Interactive Editing Interface

**The central editing workspace** where users interact with optimized prompts.

#### Three-Pane Layout

**Left Pane: Span Bento Grid**
- Visual grid showing all categorized spans
- Color-coded by semantic category
- Click any span to jump to it in the editor
- Shows confidence scores and category labels
- Responsive: Collapses to bottom drawer on mobile

**Center Pane: Main Editor**
- ContentEditable HTML editor for real-time editing
- Typewriter animation for progressive text display
- ML-powered span highlighting (video mode only)
- Click highlighted spans for instant AI suggestions
- Select any text manually to get suggestions
- Full text editing capabilities

**Right Pane: AI Suggestions Panel**
- Context-aware enhancement suggestions
- Appears when text is selected or span is clicked
- Shows 3-5 alternative phrasings
- Category-aligned suggestions
- One-click replacement

#### Floating Toolbar Features

**Copy to Clipboard**
- One-click copy of optimized prompt
- Visual feedback ("Copied!" confirmation)
- Keyboard shortcut support

**Share via UUID**
- Generates shareable link instantly
- Copies link to clipboard
- Anyone with link can view the prompt
- Preserves full context and highlights

**Export Options**
- **Text (.txt)**: Plain text format
- **Markdown (.md)**: Formatted markdown with structure
- **JSON (.json)**: Complete data including metadata, quality score, spans

**Highlight Legend**
- Toggle to show/hide category meanings
- Explains color-coding system
- Helps users understand span categorization

**Undo/Redo**
- Full edit history tracking
- Smart edit grouping (prevents every keystroke from creating history)
- Keyboard shortcuts:
  - Undo: `Cmd/Ctrl + Z`
  - Redo: `Cmd/Ctrl + Shift + Z` or `Cmd/Ctrl + Y`
- Visual indicators for available actions

**Create New Prompt**
- Quick reset to start fresh
- Clears all state and history

#### Interactive Features

**Click-to-Suggest**
```
1. User clicks highlighted span (e.g., "woman")
2. System extracts span metadata (category: subject.person)
3. AI generates 3-5 alternatives:
   - "a woman in her 30s"
   - "an elderly woman"
   - "a young woman with flowing hair"
4. User clicks suggestion to replace
```

**Text Selection Suggestions**
```
1. User selects any text manually
2. System analyzes selection context
3. Generates category-aligned suggestions
4. User can accept, modify, or dismiss
```

**Real-Time Highlighting**
- Highlights appear as text is typed or optimized
- Debounced to prevent excessive API calls
- Cached for instant re-rendering
- Persists across page reloads

**Typewriter Animation**
- Progressive text display for smooth UX
- Configurable speed
- Can be skipped for faster users
- Shows progress during optimization

#### Quality Score Display

- Visual indicator (0-100 score)
- Color-coded by quality level
- Click for detailed breakdown
- Shows expansion ratio and completeness

#### Edit History & Persistence

**Smart Edit Grouping**
- Groups rapid typing into single history entries
- Prevents history bloat
- Configurable time threshold (400ms default)

**Highlight Persistence**
- Highlights cached with fingerprint
- Fast re-rendering on text changes
- Version tracking for cache invalidation
- Survives page reloads

**State Management**
- Full undo/redo stack
- Separate stacks for text and highlights
- Efficient memory usage
- Configurable stack size (100 entries default)

---

### 7. Quality Assessment

**Automated scoring** to evaluate prompt quality.

#### Metrics

1. **Quality Score (0-100)**
   - Completeness: All necessary elements present?
   - Specificity: Sufficient detail level?
   - Structure: Well-organized and clear?
   - Clarity: Unambiguous instructions?

2. **Expansion Ratio**
   - Input: 8 words
   - Output: 127 words
   - Ratio: 15.9x expansion
   - Insight: Added substantial detail

3. **Element Coverage** (Video Mode)
   - Subject: âœ“ Present & detailed
   - Action: âœ“ Clear and filmable
   - Location: âœ“ Rich environment
   - Camera: âœ“ Technical specs
   - Lighting: âœ“ Direction & quality
   - Style: âœ“ Visual references
   - Coverage: 100%

4. **Category Distribution**
   - Subjects: 3 spans
   - Actions: 2 spans
   - Locations: 1 span
   - Lighting: 2 spans
   - Camera: 1 span
   - Style: 2 spans

#### ML-Powered Feedback

**Feature Extraction:**
- Prompt length and structure
- Vocabulary complexity
- Specificity level
- Technical term density
- Category balance

**Feedback Examples:**
```
Score: 87/100

Strengths:
âœ“ Excellent technical camera details
âœ“ Rich subject description
âœ“ Strong lighting specification

Improvements:
âš  Consider adding time of day
âš  Style reference could be more specific
ğŸ’¡ Suggestion: Add film stock reference (e.g., "35mm film")
```

---

### 8. History & Collaboration

**Smart history** with search, filtering, and sharing.

#### Features

**Automatic Saving:**
- Up to 100 optimizations per user (configurable)
- Includes input, output, mode, timestamp
- Synced to Firebase Firestore
- Available across devices

**Search & Filter:**
```
Search: "beach"
Filter: Video mode only
Sort: Most recent first

Results:
- "Beach sunset scene" (Nov 24, 2025)
- "Beach action sequence" (Nov 22, 2025)
- "Beach landscape establishing shot" (Nov 20, 2025)
```

**Share via UUID:**
```
Generate shareable link:
https://app.com/shared/abc-123-def-456

Anyone with link can:
- View the optimization
- See input and output
- Copy the prompt
- Use as template
```

**Templates:**
- Save favorites as templates
- Quick-start new optimizations
- Build personal library

---

## Who Is This For?

### 1. **AI Enthusiasts**
- Want better results from ChatGPT, Claude, etc.
- Don't know prompt engineering techniques
- Need instant improvements

**Use Case:** Transform casual AI interactions into professional-quality outputs

---

### 2. **Developers**
- Building AI-powered applications
- Need consistent, high-quality prompts
- Want to optimize LLM API costs

**Use Case:** Generate production-ready prompts programmatically via API

---

### 3. **Content Creators**
- Creating AI-generated videos (Sora, Runway)
- Need cinematic, technically-accurate prompts
- Want professional results without film school

**Use Case:** Video Concept Builder + specialized video optimization

---

### 4. **Researchers**
- Conducting AI experiments
- Need reproducible, well-structured prompts
- Want to understand prompt impact on outputs

**Use Case:** Research mode for systematic investigation plans

---

### 5. **Educators**
- Teaching with AI tools
- Creating learning materials
- Explaining complex concepts

**Use Case:** Socratic mode for guided learning sequences

---

### 6. **Teams & Enterprises**
- Standardizing AI prompt quality
- Building prompt libraries
- Monitoring AI usage and costs

**Use Case:** API integration, history/templates, quality metrics

---

## Technical Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         React Frontend (Vite)               â”‚
â”‚  - Interactive UI                           â”‚
â”‚  - Real-time highlighting                   â”‚
â”‚  - SSE streaming                            â”‚
â”‚  - Video concept builder                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ HTTP/SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Express Backend API                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Dependency Injection Container     â”‚  â”‚
â”‚  â”‚  - Service registration/resolution   â”‚  â”‚
â”‚  â”‚  - Testable architecture             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      AIModelService (Router)         â”‚  â”‚
â”‚  â”‚  - Operation-based routing           â”‚  â”‚
â”‚  â”‚  - Provider fallback                 â”‚  â”‚
â”‚  â”‚  - Circuit breakers                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚        â”‚         â”‚           â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”´â”€â”€â”€â”€â”€â”€â” â”Œâ”´â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚ LLMClient    â”‚ â”‚LLMClientâ”‚LLMClientâ”‚  â”‚
â”‚    â”‚ (OpenAI)     â”‚ â”‚ (Groq) â”‚â”‚(Gemini) â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      External Services & Storage            â”‚
â”‚  - Firebase (Auth & Firestore)              â”‚
â”‚  - Redis (Optional caching)                 â”‚
â”‚  - OpenAI API                               â”‚
â”‚  - Groq API                                 â”‚
â”‚  - Gemini API                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Technical Features

**1. Multi-Provider LLM Support**
- Generic LLMClient works with any OpenAI-compatible API
- Adapter pattern for provider-specific differences
- Automatic fallback if primary provider fails
- Zero-code provider addition via configuration

**2. Dependency Injection**
- Clean service architecture
- Fully testable components
- No module-level mutable state
- Easy to mock for testing

**3. Multi-Tier Caching**
- In-memory cache (node-cache)
- Redis cache (optional, distributed)
- Span labeling position cache
- 80%+ cache hit rate in production

**4. Circuit Breaker Pattern**
- Per-provider circuit breakers
- Prevents cascade failures
- Automatic recovery
- Configurable thresholds

**5. Performance Optimization**
- Request batching
- Request coalescing (deduplication)
- Chunked processing for large texts
- Parallel processing where possible

**6. Enterprise-Ready**
- Prometheus metrics
- Structured logging (Pino)
- Health check endpoints
- Rate limiting
- Security (Helmet, CORS, validation)

---

## Use Cases & Examples

### Use Case: AI Video Generation

**Scenario:** Filmmaker creating AI video with Sora

**Input:**
```
"cyberpunk street scene"
```

**Optimized (Video Mode):**
```
Wide establishing shot: A rain-slicked neon-lit street in a
towering cyberpunk metropolis at night, holographic advertisements
flicker across glass skyscrapers as crowds of people in luminous
clothing navigate between food stalls emitting colorful steam.

Camera: Slow descending crane shot starting 50 feet high, gradually
lowering to street level over 8 seconds. Camera moves forward through
the crowd at walking pace. Smooth gimbal movement with slight handheld
micro-vibrations for realism.

Lighting: Dominant cyan and magenta neon lighting from storefronts
and holograms. Warm amber pools of light from street vendors.
Overhead cool blue-white lights create dramatic shadows. Light
reflects off wet pavement creating mirror-like reflections.

Atmosphere: Heavy atmosphere with visible volumetric light beams
cutting through steam and light rain. Moisture on all surfaces
creates specular highlights.

Style: Blade Runner-inspired cyberpunk aesthetic. Shot on Arri Alexa
with anamorphic lens creating characteristic horizontal flares from
neon lights. Color grading: deep shadows, vibrant neons, desaturated
mid-tones. Film grain texture overlay.

Technical: 24fps for cinematic feel, 2.39:1 aspect ratio, shallow
depth of field (f/2.8) keeping foreground sharp while background
softly blurs into bokeh.

[143 words - optimized for AI video generation]
```

**Result:** Sora generates cinematic, technically-accurate cyberpunk street scene

---

---

## What Makes This Unique?

### 1. **Specialized Video Optimization**

**Only platform specifically designed for AI video generation prompts**

- Director's lexicon (shot types, camera angles, lens specs)
- Lighting terminology (quality, direction, time of day)
- Cinematography techniques
- Film style references
- 100-150 word optimal length (tested across Sora, Veo3, Runway)

**Competitors:** Generic text optimization, no video expertise

---

### 2. **Real-Time Interactive Enhancement**

**Click any part of your prompt to improve it**

- Span highlighting with semantic categorization
- Context-aware suggestions
- Category alignment
- Edit history tracking

**Competitors:** Static optimization, no interactivity

---

### 3. **Multi-Stage Progressive Enhancement**

**Best of both worlds: Speed + Quality**

- Sub-second draft (Groq Llama)
- High-quality refinement (OpenAI GPT-4)
- Parallel span labeling
- Smooth streaming updates

**Competitors:** Single optimization, long wait times

---

### 4. **Enterprise-Grade Architecture**

**Production-ready from day one**

- Multi-provider LLM support with fallback
- Circuit breakers for reliability
- Multi-tier caching (80%+ hit rate)
- Prometheus metrics
- Kubernetes-ready with auto-scaling
- Request batching (60% API call reduction)

**Competitors:** Proof-of-concept code, not production-ready

---

### 5. **Video-Specific Expertise**

**Specialized for cinematic AI video generation**

- Technical camera specifications
- Lighting and composition guidance
- Film style references and color grading
- Shot-by-shot breakdowns
- Platform-specific optimizations (Sora, Veo3, RunwayML, Kling, Luma)

**Competitors:** One-size-fits-all approach, no video expertise

---

## Technology Stack

### Frontend
- **React 18.2** - Modern UI framework
- **Vite 7.1** - Lightning-fast build tool
- **Tailwind CSS** - Utility-first styling
- **TypeScript** - Type safety

### Backend
- **Express 4.21** - Web framework
- **Firebase** - Auth & database
- **Pino** - Structured logging
- **Prometheus** - Metrics
- **TypeScript** - Type safety

### LLM Integration
- **OpenAI** (GPT-4o-mini) - Quality
- **Groq** (Llama 3.1 8B) - Speed
- **Gemini** (Pro) - Diversity
- **Generic LLMClient** - Provider-agnostic

### Infrastructure
- **Docker** - Containerization
- **Kubernetes** - Orchestration
- **Redis** - Distributed caching
- **Grafana** - Monitoring dashboards

---

## Performance & Scale

### Speed
- **Draft generation**: < 300ms (Groq)
- **Span labeling**: < 250ms (cached 80%+)
- **Full optimization**: < 2.5s (with refinement)
- **API response time**: < 500ms (p95)

### Reliability
- **Uptime**: > 99.9% target
- **Error rate**: < 0.1%
- **Circuit breaker**: Prevents cascade failures
- **Multi-provider fallback**: Automatic failover

### Cost Efficiency
- **80%+ cache hit rate**: Reduces LLM API costs
- **Request batching**: 60% reduction in concurrent calls
- **Two-tier optimization**: Cheap draft + premium refinement
- **Request coalescing**: Deduplicates identical requests

### Scalability
- **Kubernetes HPA**: Auto-scales 2-10 pods
- **Stateless architecture**: Horizontal scaling
- **Redis caching**: Distributed cache layer
- **Edge deployment**: Cloudflare Workers support

---

## Getting Started

### Quick Start (5 minutes)

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/prompt-builder.git
cd prompt-builder

# 2. Install dependencies
npm install

# 3. Configure environment
cp .env.example .env
# Edit .env with your API keys

# 4. Start the application
npm start

# 5. Open browser
# http://localhost:5173
```

### Requirements
- Node.js >= 20.0.0
- Firebase account (free)
- OpenAI API key
- Optional: Groq API key (free, for fast drafts)

---

## Project Status

### Current Version: 0.1.0

### Recent Major Updates

**November 2025: LLM Architecture Refactoring**
- Generic LLMClient replacing provider-specific clients
- AIModelService unified router
- Zero-code provider addition
- Fixed critical span labeling bugs

**October 2025: Span Labeling System**
- Comprehensive text categorization
- Batch processing API
- Chunked processing for large texts
- 60% API call reduction

**September 2025: Two-Stage Optimization**
- Fast draft generation (Groq)
- Parallel span labeling
- SSE streaming support
- Progressive enhancement

---

## Future Roadmap

### Q1 2026
- [ ] GPT-4o support for vision-based optimization
- [ ] Prompt template marketplace
- [ ] Team collaboration features
- [ ] Advanced analytics dashboard

### Q2 2026
- [ ] Browser extension (Chrome, Firefox)
- [ ] Slack/Discord integration
- [ ] Webhook support for automation
- [ ] Multi-language support

### Q3 2026
- [ ] Mobile applications (iOS, Android)
- [ ] Voice input for prompt optimization
- [ ] A/B testing framework for prompts
- [ ] Enterprise SSO integration

---

## License

MIT License - Free for commercial and personal use

---

## Support & Community

- **Documentation**: [Full Docs](README.md)
- **API Reference**: [API Docs](docs/API.md)
- **GitHub**: [Issues & Discussions](https://github.com/yourusername/prompt-builder)
- **Discord**: [Community Chat](#)

---

**Built with â¤ï¸ for the AI community**

*Making expert-level prompts accessible to everyone*
